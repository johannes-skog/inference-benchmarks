{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15cda582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c217b14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx\n",
    "!pip install onnxruntime\n",
    "!pip install onnxruntime-gpu\n",
    "!pip install torch-tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fcc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "deaa1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "import onnx\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "class BenchmarkModelTensorRT():\n",
    "    \n",
    "    def __init__(self, trt_model_path):\n",
    "        \n",
    "        self._model = torch.jit.load(trt_model_path)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        return self._model(inputs)\n",
    "    \n",
    "class BenchmarkModelTensorONNX():\n",
    "    \n",
    "    def __init__(self, onnx_path, device: str):\n",
    "        \n",
    "        self._session = onnxruntime.InferenceSession(\n",
    "            onnx_path,\n",
    "            providers=['CUDAExecutionProvider'] if device == 'cuda' else ['CPUExecutionProvider'],\n",
    "            verbose=True,\n",
    "        )\n",
    "        \n",
    "        self._input_names = [x.name for x in self._session.get_inputs()]\n",
    "        \n",
    "        self._output_name = self._session.get_outputs()[0].name\n",
    "        \n",
    "        print(self._output_name)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        inputs = {k: v.cpu().numpy().astype(np.int64) for k, v in inputs.items() if k in self._input_names}\n",
    "        \n",
    "        return self._session.run([self._output_name], inputs)[0]\n",
    "        \n",
    "class BenchmarkModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, model, model_path: str):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self._model = model\n",
    "        self._model_path = model_path \n",
    "        \n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        \n",
    "    def forward(self, *args, **kwargs):\n",
    "        \n",
    "        return self._model.forward(*args, **kwargs)\n",
    "    \n",
    "    def export_to_onnx(\n",
    "        self,\n",
    "        dummy_input: Dict[str, torch.Tensor],\n",
    "        dynamic_axis: Dict,\n",
    "        device: str,\n",
    "    ):\n",
    "        \n",
    "        self._model.eval()\n",
    "        \n",
    "        onnx_path = os.path.join(self._model_path, \"onnx\")\n",
    "\n",
    "        torch.onnx.export(\n",
    "            self._model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            output_names=[\"output\"],\n",
    "            input_names=list(dummy_input.keys()),\n",
    "            opset_version=12,\n",
    "            dynamic_axes=dynamic_axis,\n",
    "        )\n",
    "        \n",
    "        return BenchmarkModelTensorONNX(onnx_path, device=device)\n",
    "\n",
    "    def convert_to_tensorrt(\n",
    "        self,\n",
    "        dummy_input,\n",
    "        min_shape: List[int],\n",
    "        max_shape: List[int],\n",
    "        opt_shape: List[int],\n",
    "        fp16_mode=False,\n",
    "    ):\n",
    "        \n",
    "        self._model.eval()\n",
    "        \n",
    "        rt_model = trt.ts.convert(\n",
    "            self._model,\n",
    "            inputs=[dummy_input],\n",
    "            fp16_mode=fp16_mode,\n",
    "            min_shape=min_shape,\n",
    "            opt_shape=opt_shape,\n",
    "            max_shape=max_shape\n",
    "        )\n",
    "        \n",
    "        trt_model_path = os.path.join(self._model_path, \"tensorrt\")\n",
    "        \n",
    "        torch.jit.save(rt_model, trt_model_path)\n",
    "        \n",
    "        return BenchmarkModelTensorRT(trt_model_path)\n",
    "    \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "class TextClassification(BenchmarkModel):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"nateraw/bert-base-uncased-imdb\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        \n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(\n",
    "           model_name\n",
    "        )\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        super().__init__(model, model_name.replace(\"/\", \"-\"))\n",
    "        \n",
    "    def export_to_onnx(self, device: str):\n",
    "        \n",
    "        dummy_input = {\n",
    "            \"input_ids\": torch.Tensor([[1, 2, 3]]).long(),\n",
    "            \"attention_mask\": torch.Tensor([[0, 1, 0]]).long()\n",
    "        }\n",
    "        \n",
    "        dynamic_axes = {\n",
    "            'input_ids': {0: 'batch_size', 1: 'sequence_length'},\n",
    "            'attention_mask': {0: 'batch_size', 1: 'sequence_length'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "        \n",
    "        return super().export_to_onnx(\n",
    "            dummy_input,\n",
    "            dynamic_axes,\n",
    "            device=device,\n",
    "        )\n",
    "            \n",
    "    def forward_text(self, text: str):\n",
    "        \n",
    "        tokens = self._tokenizer(text, return_tensors=\"pt\")\n",
    "        \n",
    "        return self.forward(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a66fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2ec927ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 18:42:19.278158690 [W:onnxruntime:, session_state.cc:1136 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2023-04-20 18:42:19.278174619 [W:onnxruntime:, session_state.cc:1138 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    }
   ],
   "source": [
    "onnx_model = model.export_to_onnx(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665cb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6df5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5b6a6422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.181607484817505"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "\n",
    "model.eval().cuda()\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = {k: v.cuda() for k,v in model._tokenizer(\"This was such a good movie\", return_tensors=\"pt\").items()}\n",
    "    inputs = model.forward(**tokens)\n",
    "    \n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5700845a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.97001314163208"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "s = time.time()\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = model._tokenizer(\"This was such a good movie\", return_tensors=\"pt\")\n",
    "    inputs = onnx_model.forward(tokens)\n",
    "    \n",
    "e = time.time()\n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model._tokenizer(\"This was such a good movie\", return_tensors=\"pt\")[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4de833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f5f436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.2428, -1.3491,  3.8788]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward_text(\"This was such a good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbbe0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee76690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0833a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-tensorrt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
